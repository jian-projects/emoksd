model:
  name: emoskd
  arch: roberta
  framework: 
  scale: large
  drop_rate: 0.1
  use_adapter: false
  use_lora: true
  use_rnn: false 
  optim_sched: ['AdamW', 'cosine']
  weight: 1.0

train:
  device_ids: [0]
  epochs: 6
  early_stop: 3
  batch_size: 16
  log_step_rate: 1.0
  learning_rate: 0.0003
  learning_rate_pre: 0.0003
  save_model: 0
  inference: 0
  do_test: true
  wandb: 0
